{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 670 (CNMeM is enabled with initial size: 75.0% of memory, cuDNN 5005)\n",
      "/home/krautcat/cuda/ml-4/cifar-10/theano-env/local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем предобработанную базу изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirpath='cifar-100-python'\n",
    "# load training data\n",
    "X, y = [], []\n",
    "\n",
    "path = '%s/train' % dirpath\n",
    "with open(path, 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "X.append(batch['data'])\n",
    "y.append(batch['coarse_labels'])\n",
    "\n",
    "X = np.concatenate(X) \\\n",
    "      .reshape(-1, 3, 32, 32) \\\n",
    "      .astype(np.float32)\n",
    "y = np.concatenate(y).astype(np.int32)\n",
    "\n",
    "# split into training and validation sets\n",
    "ii = np.random.permutation(len(X))\n",
    "X_train = X[ii[100:]]\n",
    "y_train = y[ii[100:]]\n",
    "X_valid = X[ii[:100]]\n",
    "y_valid = y[ii[:100]]\n",
    "\n",
    "# load test set\n",
    "path = '%s/test' % dirpath\n",
    "with open(path, 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "X_test = batch['data'] \\\n",
    "         .reshape(-1, 3, 32, 32) \\\n",
    "         .astype(np.float32)\n",
    "y_test = np.array(batch['coarse_labels'], dtype=np.int32)\n",
    "\n",
    "# normalize to zero mean and unity variance\n",
    "offset = np.mean(X_train, 0)\n",
    "scale = np.std(X_train, 0).clip(min=1)\n",
    "\n",
    "X_train = (X_train - offset) / scale\n",
    "X_valid = (X_valid - offset) / scale\n",
    "X_test = (X_test - offset) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_cnn(input_var=None,\n",
    "              crp_num_filters=64, crp_filter_size=3,):\n",
    "    \n",
    "    network = lasagne.layers.InputLayer(shape=(None, 3, 32, 32),\n",
    "                                        input_var=input_var)\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, \n",
    "            num_filters = 3 * crp_num_filters, \n",
    "            filter_size = (crp_filter_size, crp_filter_size),\n",
    "            nonlinearity = lasagne.nonlinearities.rectify,\n",
    "            W = lasagne.init.GlorotUniform())\n",
    "\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, \n",
    "            num_filters = 2 * crp_num_filters,\n",
    "            filter_size = (crp_filter_size, crp_filter_size),\n",
    "            nonlinearity = lasagne.nonlinearities.rectify,\n",
    "            W = lasagne.init.GlorotUniform(gain='relu'))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, \n",
    "            num_filters = crp_num_filters,\n",
    "            filter_size = (crp_filter_size, crp_filter_size),\n",
    "            nonlinearity = lasagne.nonlinearities.rectify,\n",
    "            W = lasagne.init.GlorotUniform(gain='relu'))\n",
    "    \n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units = 128,\n",
    "            nonlinearity = lasagne.nonlinearities.rectify)\n",
    "\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units = 20,\n",
    "            nonlinearity = lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = build_cnn(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krautcat/cuda/ml-4/cifar-10/theano-env/local/lib/python2.7/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    }
   ],
   "source": [
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "            loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                        dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = test_prediction.argmax(-1)\n",
    "f_predict = theano.function([input_var], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], \n",
    "                           loss, \n",
    "                           updates=updates,\n",
    "                           allow_input_downcast=True)\n",
    "\n",
    "val_fn = theano.function([input_var, target_var], \n",
    "                         [test_loss, test_acc],\n",
    "                         allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "val_acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train: 2.6062749833, val: 2.11477398872, accuracy: 0.380952378114, time: 89.6802070141 sec\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch in iterate_minibatches(X_train, y_train, BATCH_SIZE, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "    \n",
    "    # validation accuracy\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    \n",
    "    for batch in iterate_minibatches(X_valid, y_valid, BATCH_SIZE, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    val_acc /= val_batches\n",
    "    val_acc_history.append(val_acc)\n",
    "    \n",
    "    # keep track of the best model based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        # make a copy of the model\n",
    "        best_val_acc = val_acc\n",
    "        best_model = lasagne.layers.get_all_param_values(network)\n",
    "        \n",
    "    print(\"Epoch: {}, train: {}, val: {}, accuracy: {}, time: {} sec\".format(epoch, \n",
    "                                                train_err/train_batches,\n",
    "                                                val_err/val_batches,\n",
    "                                                val_acc,\n",
    "                                                time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(np.array(loss_history).clip(max=3))\n",
    "# plt.xlabel('iteration')\n",
    "# plt.ylabel('loss')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(val_acc_history)\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "lasagne.layers.set_all_param_values(network, best_model)\n",
    "\n",
    "for i in range(10000):\n",
    "    y_true.append(int(y_test[i]))\n",
    "    y_pred.append(f_predict([X_test[i]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(CM, annot=True, fmt=\"d\", linewidths=.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
